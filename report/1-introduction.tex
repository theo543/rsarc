\chapter{Introduction}

Data corruption is a significant issue in software and hardware systems, which can lead to data loss, incorrect program behavior, and system failures.

It is impossible in general to prevent errors due to uncontrolled factors such as electromagnetic interference, cosmic rays, or hardware defects, not to mention software bugs.
Even data stored in memory or in CPU registers and cache can rarely be corrupted, which must be accounted for in large-scale systems where it is statistically likely that errors will occur.
\cite{radiation-errors, dram-errors-in-the-wild}

Error detection and correction is a major area of research in the field of computer science, and many companies invest heavily in ensuring the robustness of their systems against random errors:

\begin{itemize}[nosep]
    \item Major cloud storage providers often guarantee that data is stored redundantly and split across multiple locations, and that it is regularly scanned for errors. \cite{azure, backblaze, google-cloud}
    \item Server hardware often includes ECC memory, which can transparently correct certain errors in RAM, and which will crash the system instead of silently saving corrupted data when it cannot be corrected. \cite{ecc-market, azure-ecc}
    \item Modern filesystems such as ZFS and Btrfs automatically detect block-level errors using checksums, and have built-in support for redundancy. \cite{zfs-vs-btrfs}
    \item RAID technology (Redundant Array of Independent Disks) can combine multiple disk drives into one logical unit, using some disks for redundancy. \cite{raid-case}
\end{itemize}

While merely detecting errors only requires checksums or hashes, recovery from errors without needing to keep a full second copy of the data requires error-correcting codes (ECC).

Reed-Solomon codes are a major family of error-correcting codes, with a wide range of applications, such as in CDs, DVDs, radio communication, QR codes, RAID, and many more.

A less common application of error-correcting codes, which this project focuses on, is recovering errors at the level of a file.
Since disk errors often result in bad sectors, not necessarily full disk failures, it is useful to be able to repair a file with a few corrupt sectors.

For this purpose, I implemented a multithreaded CLI utility which generates parity data to repair errors using interleaved Reed-Solomon codes.
The program is written in Rust, a language well-suited for implementing fast system utilities, and which enables safe multithreading and memory management.

The file is divided into $N$ data blocks, and $M$ parity blocks are generated and stored in a separate file.
This scheme can be viewed as RAID with $N + M$ drives, or as interpreting the data as a matrix with $N + M$ rows, where each column is an independent Reed-Solomon code, the latter $M$ rows being the parity file.
This has the drawback of a non-contiguous access pattern, which harms I/O performance.

Errors are detected using hashes of each block.
Since a single error is enough to corrupt a block, the program is best suited at recovering from burst errors, such as those caused by a bad sector, which are clustered together in few blocks.

Since a block size close to the disk sector size is desirable to minimize the impact of errors, the amount of symbols in a code can be very large.
This requires algorithms which can handle large codes efficiently, with sub-quadratic time complexity.

I implemented a Reed-Solomon code which supports up to $2^{64}$ blocks, and most importantly allows $O(n \log n)$ FFT-like transforms which can be used for efficient encoding and decoding,
by using a polynomial basis introduced in \cite{novel-poly} over polynomials in the finite field \GF{64}.

The implementation also uses efficient algorithms for the finite field arithmetic which is at the root of Reed-Solomon codes, using a modern CPU feature - carry-less multiplication \cite{intel-clmul} - for fast finite field multiplication.

This thesis will outline the mathematics of finite field arithmetic and Reed-Solomon codes, the polynomial basis and transforms used for $O(n \log n)$ encoding and decoding, the high-level architecture of the implementation, and its performance characteristics.
